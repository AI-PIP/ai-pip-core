# ISL - Instruction Sanitization Layer

> **Capa de Sanitizaci√≥n de Instrucciones** - Segunda capa del protocolo AI-PIP

## üìã Descripci√≥n General

La **Instruction Sanitization Layer (ISL)** es la segunda capa del protocolo AI-PIP. Su funci√≥n principal es sanitizar el contenido recibido de CSL aplicando diferentes niveles de sanitizaci√≥n seg√∫n el nivel de confianza de cada segmento.

### Principios Fundamentales

- **Sanitizaci√≥n Diferenciada**: Nivel de sanitizaci√≥n basado en trust level
- **Detecci√≥n de Prompt Injection**: Identifica patrones maliciosos
- **Preservaci√≥n de Original**: Mantiene el contenido original para auditor√≠a
- **Pol√≠ticas Configurables**: Aplica pol√≠ticas de seguridad

## üéØ Funcionalidades Principales

### 1. Sanitizaci√≥n por Nivel de Confianza

ISL aplica diferentes niveles de sanitizaci√≥n seg√∫n el `trust` level del segmento:

- **TC (Trusted Content)**: Sanitizaci√≥n m√≠nima
- **STC (Semi-Trusted Content)**: Sanitizaci√≥n moderada
- **UC (Untrusted Content)**: Sanitizaci√≥n agresiva

```typescript
import { sanitize } from '@ai-pip/core/isl'

const islResult = sanitize(cslResult)

// Cada segmento sanitizado tiene:
// - originalContent: contenido original preservado
// - sanitizedContent: contenido sanitizado
// - sanitizationLevel: 'minimal' | 'moderate' | 'aggressive'
```

### 2. Detecci√≥n de Prompt Injection

ISL detecta patrones de prompt injection mediante:

- **PiDetection**: Detecci√≥n individual de patrones
- **PiDetectionResult**: Resultado agregado con score y acci√≥n
- **Pattern Matching**: Identificaci√≥n de patrones maliciosos

### 3. Pol√≠ticas de Seguridad

ISL aplica pol√≠ticas configurables mediante `PolicyRule`:

- **Blocked Intents**: Intenciones expl√≠citamente bloqueadas
- **Sensitive Scope**: Temas sensibles que requieren validaci√≥n
- **Role Protection**: Roles protegidos que no pueden ser sobrescritos
- **Immutable Instructions**: Instrucciones que no pueden ser modificadas
- **Context Leak Prevention**: Prevenci√≥n de fuga de contexto

### 4. Anomaly Scoring

ISL calcula scores de anomal√≠a para detectar comportamientos sospechosos:

- **AnomalyScore**: Score de anomal√≠a (0-1)
- **AnomalyAction**: Acci√≥n recomendada (ALLOW, WARN, BLOCK)

## üì¶ Componentes

### Funciones Principales

- **`sanitize(cslResult: CSLResult): ISLResult`** - Funci√≥n principal de sanitizaci√≥n

### Value Objects

- **`PolicyRule`** - Regla de pol√≠tica de seguridad
- **`PiDetection`** - Detecci√≥n individual de prompt injection
- **`PiDetectionResult`** - Resultado agregado de detecci√≥n
- **`AnomalyScore`** - Score de anomal√≠a
- **`Pattern`** - Patr√≥n de detecci√≥n

### Tipos

- **`ISLInput`** - Input para sanitizaci√≥n (CSLResult)
- **`ISLResult`** - Resultado de sanitizaci√≥n
- **`ISLSegment`** - Segmento sanitizado
- **`RemovedInstruction`** - Instrucci√≥n removida durante sanitizaci√≥n
- **`RiskScore`** - Score de riesgo (0-1)
- **`AnomalyAction`** - Acci√≥n recomendada

## üîÑ Flujo de Procesamiento

```
CSLResult (segmentos clasificados)
    ‚Üì
Determinar nivel de sanitizaci√≥n (getSanitizationLevel)
    ‚Üì
Sanitizar contenido (sanitizeContent)
    ‚Üì
Detectar prompt injection (opcional)
    ‚Üì
Calcular anomaly score (opcional)
    ‚Üì
Aplicar pol√≠ticas (PolicyRule)
    ‚Üì
ISLResult (segmentos sanitizados + metadata)
```

## ‚úÖ Garant√≠as

1. **Preservaci√≥n**: El contenido original se mantiene en `originalContent`
2. **Trazabilidad**: El linaje se actualiza con entrada ISL
3. **Fail-Secure**: Contenido no confiable recibe sanitizaci√≥n agresiva
4. **Configurabilidad**: Pol√≠ticas personalizables mediante PolicyRule

## üìù Ejemplo de Uso

```typescript
import { sanitize, createPolicyRule } from '@ai-pip/core/isl'
import { segment } from '@ai-pip/core/csl'

// 1. Segmentar contenido (CSL)
const cslResult = segment({
  content: 'User input with malicious pattern',
  source: 'API',
  metadata: {}
})

// 2. Sanitizar contenido (ISL)
const islResult = sanitize(cslResult)

// Cada segmento sanitizado tiene:
// - id: identificador √∫nico
// - originalContent: contenido original preservado
// - sanitizedContent: contenido sanitizado
// - trust: nivel de confianza del segmento original
// - lineage: linaje actualizado con entrada ISL
// - piDetection: detecci√≥n de prompt injection (opcional)
// - anomalyScore: score de anomal√≠a (opcional)
// - instructionsRemoved: instrucciones removidas
// - sanitizationLevel: nivel aplicado

// 3. Crear pol√≠tica de seguridad
const policy = createPolicyRule(
  '1.0.0',
  ['malicious_intent'],           // Blocked intents
  ['sensitive_data'],             // Sensitive scopes
  {
    protectedRoles: ['system'],    // Protected roles
    immutableInstructions: ['do_not_modify']
  },
  {
    enabled: true,
    blockMetadataExposure: true,
    sanitizeInternalReferences: true
  }
)
```

## üîó Integraci√≥n con CSL y CPE

### Entrada desde CSL

ISL recibe `CSLResult` con segmentos clasificados y sus trust levels.

### Salida hacia CPE

ISL produce `ISLResult` que contiene:

```typescript
ISLResult {
  segments: ISLSegment[]      // Segmentos sanitizados
  lineage: LineageEntry[]     // Linaje actualizado
  metadata: {
    totalSegments: number
    sanitizedSegments: number
    blockedSegments: number
    instructionsRemoved: number
  }
}
```

## ‚ö†Ô∏è Limitaciones del Core

El core de ISL **NO incluye**:
- Implementaci√≥n completa de detecci√≥n de patrones (estructura b√°sica)
- Normalizaci√≥n avanzada de contenido (va al SDK)
- Serializaci√≥n de resultados (va al SDK)
- Servicios con estado (van al SDK)

Estas funcionalidades se implementan en el SDK o en capas superiores.

